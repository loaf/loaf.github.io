---
title: 《人工智能的未来》阅读笔记
date: 2022-01-27
category: 随笔
tags:
  - 人工智能
  - AI
description: How to Create a Mind-The Secret of Human Thought Revealed...

---

<!-- more -->

作者: [美] 雷·库兹韦尔
出版社: 浙江人民出版社
原作名: How to Create a Mind: The Secret of Human Thought Revealed
译者: 盛杨燕
出版年: 2016-3
页数: 325
定价: 79.90元
装帧: 精装
丛书: “机器人与人工智能”书系
ISBN: 9787213071478
[豆瓣读书](https://book.douban.com/subject/26716264/)
[在线阅读](http://my.52ds.net:32766/read/5895/epub#epubcfi(/6/2[titlepage]!/8/1:0))

>“不断加速的科技进步，以及其对人类生活模式带来的改变，似乎把人类带到了一个可以称之为‘奇点’的阶段。在这个阶段过后，我们目前所熟知的人类的社会、艺术和生活模式，将不复存在。”
——波兰裔美籍数学家乌拉姆（Stanlalw Marcin Ulam）
Tribute to John von Neumann, Bulletin of American Mathematic Society，64[nr3，part2]：1-49

>我之前出版过3本有关技术的书，其中，《智能机器时代》（Age of Intelligent Machines），写于20世纪80年代，出版于1989年；《灵魂机器时代》（Age of Spiritual Machines），写于90年代中期到末期，出版于1999年；《奇点临近》，写于21世纪初，出版于2005年，其主要思想是关于一个固有的不断加快的演化进程（因抽象意识水平的不断提升而导致），以及其产物的复杂性和能力的指数级增长。

思想实验1：地质的隐喻

思想实验2：驾乘光束

>如果一个年轻人只需空想和纸笔就足以彻底改变物理学观念，那么对于熟知之物，我们理应能获取更深刻的认识。毕竟，在清醒的每一刻，我们都在思考。

当我们谈论“创造性”时，往往会忽略了一点，就是，这些创造性其实是对已掌握模式的一种调用，可能还是一些因为记忆或者别的原因造成的错误调用。因为好的结果，成为了新的经验的一部分。这里谈到卡斯帕罗夫学习了大约10万个棋局，这也解释了，为什么创造性并不能跨专业，而棋感只会由高手产生，因为这些高手在成长过程中投入了大量的精力，积累了大量的经验。

人体所有的器官是大脑信息的输入设备，大脑并不是记录所见所闻，而是将输入的信息做处理，通过模式判断，进行分类及关联，形成一个图谱。这就是说，我们一直看重“原始数据”，其实“原始数据”是最不重要的。我们看重原始数据是因为我们不相信自己的判断，怕自己做出了错误的决策，但是，错误的决策其实是人类决策中必不可少的一个部分，解决方法是，让更多的人来参与其中，面对相同的原始数据，各自做出决策。真相不是事实上发生了什么，而是共识。

假如有一天，我们可以把自己的意识上传，那么需要保存的是什么呢？我们是不是需要在活着的时间布满传感器，记录下发生过的一切？或者说，在找到大脑意识的物质基础前，所谓的意识上传只能是幻想，而且这个难度比我们想象中更大。

对于资料也是这样，打的标签越多，理论上越容易检索，但是打正确的标签这个动作的难度却很大，或者，我们还要加上标签与标签之间的关联，或者，我保存一个资料时，其实是把资料化成一系列的标签和概念，然后这些标签和概念是相同的层级的数据，这些数据相互联系，一篇文章，其实就是一个概念的集合，这就是**信息混沌汤**。

但是原始数据是会溶化到其中吗？好像也不能如此，比如我要学习编程，一段代码的思想是可以按上面的方法理解的，但是句法、规则我还是要记忆下来的。不按指定的方式来书写，是不行的。记忆仍是重要的部分。

好吧，总结一下，对于一件事、一个经历、一篇文章，一门教程，总是由一系列的知识点（原子态）和一系列的混沌信息组成，知识点是需要记忆的，然后剩下的就是一系列的标签，比如“反讽”、“有趣”、“需要记住”、“可能有用”……等等一系列或者有关，或者无关的概念、感觉等乱七八糟的信息混沌汤组成。然后时间会不停地修正，或者强化某些概念，或者丢弃某些信息。外界的输入，也在不停地强化或弱化这些信息，从而形成某些共识。

错误其实是进化的基础，追求正确，只能解决已有的问题，而创造性，则是基于错误的。基因突变就是一个很好的例子。

所以说，我们说机器没有灵魂，就是说机器没有创造性，而这只是因为我们没有正确地使用机器。

如果用人类学习来比拟机器学习的话，人是通过经验来学习，而这些经验其实就是长者的教导和生活经历中得到的教训，机器学习是通过人为给指定的材料打标签，其实，如果拟人的话，机器只要能判断出所有的输入资料中，哪些是哪些的标签即可。所有的输入都是材料，同时，又都是另一个材料的标签值。

>梦是发散思维的实例。梦可以说是有意义的，因为一个想法触发另一个的现象是基于我们大脑新皮质中模式的实际联系而发生的。在一定程度上，梦之所以无意义，是因为我们尝试用虚构的能力对其进行修补。

梦中的思考和清醒时的思考存在的关键区别在于“禁忌”。

>事实证明，放宽职业禁忌对创造性地解决问题非常有效。

>想一想该项研究的启示：它意味着物理上相对远离的新皮质区域，以及被认为概念很不一样的新皮质区域（原始视觉线索对抽象语言概念），本质上来说使用的却是相同的算法。负责处理不同模式类型的区域可以相互替代。

这意味着人脑中计算单元可能还真是一致的，只是不同的使用方法使得它们看上去各不相同，这样，机器模拟人脑也就是有了理论基础。

**新皮质**是进化程度较高级的皮质。是哺乳动物大脑皮质的大部分，在脑半球顶层，大约2～4毫米厚，分为六层。与一些高等功能如知觉、运动指令的产生、空间推理、意识及人类语言有关系。
**丘脑**是感觉的高级中枢，是最重要的感觉传导接替站。
>丘脑被视为前期加工过的感官信息进入新皮质的通道。
>然而，丘脑最显著的作用却是它与新皮质的持续交流。

**海马体**最主要的作用就是记住新颖的事件。当感官信息流经新皮质，新皮质会判定这种经历是否新颖，然后将其呈现给海马体。
**小脑**是曾经控制几乎所有原始人类运动的旧脑区域。

>和快乐有关的区域是伏隔核（nucleus accumbens）。
快乐也由多巴胺和血清素这些化学物质调节。
人类新皮质的主要职责是让我们成为快乐和恐惧的主人，而不是它们的奴隶。

>人类大脑每个半球都有杏仁核，它包括一个由几个小叶组成的杏状区域。杏仁核也是旧脑的一部分，会处理一系列情绪反应，特别是恐惧。

>旧脑通过控制快乐和恐惧经历来定好议程，而新脑则一直尝试着理解旧脑相对原始的公式并力图控制自己的议程。

>人类的卓越能力，主要归功于大脑脑岛中的纺锤体细胞。大脑新皮质某些区域的优化，使其更善于处理联合模式，这就是天分的由来。跨领域合作和非生物大脑新皮质的云端存储，将让我们更富有创造力。从进化观点看，爱情存在的本身就是为了满足大脑新皮质的需求。

>创造力的一个重要方面是找到绝佳隐喻的过程——代表某种其他事物的标志。

这也是一种理解能力和学习能力，如果你能知道别人所说的言外之意，就是说明你有足够的共情能力，你就能学习到许多你不必亲身经历的经验。这也是文化传承的必要前提。

而这种能力还表现在，你能将经验跨专业跨领域使用，这就是创造性了。所以我们需要更多的知识，未必是本专业内的。

>获得更大创造力的一种方式就是有效地聚集更多的新皮质。

>拓展可用新皮质的一种方法就是通过多人合作。


>即使你没有真正地亲自经历过心醉神迷的爱情，你也肯定听说过。公平地说，世界艺术的相当一部分——故事、小说、音乐、舞蹈、绘画、电视剧和电影，在早期都是由爱情故事赋予灵感创作出来的。
最近，科学也加入了进来，而且我们现在能识别出当某人坠入爱河时发生的生理变化。多巴胺被释放出来，制造了幸福与欢乐的感觉。去甲肾上腺素水平迅速升高，导致心跳加速和整体的兴奋感。这些化学物质，连同苯乙烯，使人变得兴奋、充满活力、注意力集中、食欲不振和渴望得到想要得到的物品。有意思的是，伦敦大学学院的最新研究表明，恋爱中的人血清素水平会降低，这与强迫症患者的情况相似。多巴胺和去甲肾上腺素的高水平解释了短期注意力的提高、幸福感和对早恋的渴望的原因。

>从进化的观点来看，爱情存在的本身就是为了满足新皮质的需求。如果我们没有新皮质，性欲对保证繁衍来说已经足够了。

所以说，爱情是灵感的来源是有道理的。

>动物行为的进化的确是一个学习的过程，但是这种进化是整个物种群体的学习，而不是个体的学习。进化的成果通过DNA遗传给下一代。

如果动物行为的习得可以通过DNA遗传，则说明，有些知识是可以直接灌输的。只要方法正确，我们也许真的可以通过聪明丸来学习知识。

而用机器智能模拟生物智能 时，这种学习速度更是提高了几百万倍。
即使不是取代，而是作为人体大脑新皮质的补充，都会令人类成为一个新的物种。


[蓝脑计划](https://www.epfl.ch/research/domains/bluebrain/),当时的[相关报道](https://www.wired.com/2013/05/neurologist-markam-human-brain/)，2013年由亨利·马克拉姆启动。现在[看来是失败了](https://www.zhihu.com/question/32385886/answer/795723388)。
类似的还有一个欧盟的[人脑计划](https://www.humanbrainproject.eu/en/)

神经网络模拟神经元的原理，最终并不成功的原因，既可能是因为模拟的精度、感知器的性能等因素，也可能是因为这原理本不正确。

语音识别也面临相同的问题，只要是不能理解语意，识别的效率肯定是有问题的，人类听懂语音，其实大部分是靠猜，在一定的语境下，联系上下文，评估内容。

当前的语音识别本质上是一个数学运算，将声音转化为数字信号，然后取样，过滤掉大多数的数据，然后这些数据匹配最接近的标准发音数据。也许技术的进步在于，对结果的联想优化，或者通过人们修正输入的文字，修改标准发音库。

## 隐马尔可夫模型
[隐马尔可夫模型](:/6288abcc076340c0a7ed26f0b78e2edf)
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250903153504245.png)

语料库中每个音节都会保存一个与其它章节产生联结的概率。

[进化（遗传）算法](:/34154506fbd04941be69518042d011b9)
>遗传算法的关键是：人类并不直接将解决方案编程，而是让其在模拟竞争和改善的重复过程中自行找到解决方案。

[Cyc项目](https://cyc.com/) 机器推理平台

以数学为基础创造人工大脑，怎么看都有点不靠谱，正如数学的特点，作者是将大脑可能的运作过程，抽象又抽象了，就这么简单化后的理论，却试图产生超越生物学大脑的功能，是太乐观了点。

美国数学家克劳德·香农（Claude Shannon）在《贝尔系统技术杂志》（Bell System Technical Journal）上发表了具有里程碑意义的论文《通信的数学理论》（A Mathematical Theory of Communication），提出噪声通道编码理论。**秘诀就在于冗余。**


**计算的通用性。**
>1936年，艾伦·图灵提出“图灵机”。
>邱奇-图灵论的一种“强有力”的诠释在本质上将人的思想或认知与机器的计算等同起来，其基本论点是人脑同样遵循自然定律，因此它的信息处理能力不可能超过机器，即也不可能超越图灵机。

>图灵向我们展示了无法解决的问题和可以解决的问题一样多。数学家和哲学家库尔特·哥德尔（Kurt Gödel）在他1931年提出的“不完全定理”（incompleteness theorem）中提出了类似的结论。我们因此面临一个令人困惑的情形，即我们可以定义一个问题，也可以证明唯一的答案存在，但却永远得不到答案。

**冯·诺依曼结构**
>在写于1945年6月30日一篇名为《关于EDVAC的报告草案》（First Draft of a Report on The EDVAC）的论文中，冯·诺依曼提出了自此以后主导计算领域的理论，即冯·诺依曼模型——包括一个进行计算和逻辑运算的中央处理器，一个存储程序和数据的内存单元，一个大容量存储器，一个程序计数器，以及输出/输入通道。
查尔斯·巴贝奇（Charles Babbage）。1837年首次描述了一种名为分析机（Analytical Engine）的机器，该机器就体现了冯·诺依曼的理念.
英国作家艾达·拜伦（Ada Byron）——勒芙蕾丝伯爵夫人、诗人罗德·拜伦的唯一合法继承人，可以说是世界上第一个计算机程序设计员。她为分析机编写了程序，即今天软件工程师所熟知的“查表法”。

>冯·诺依曼的基本见解是，**计算机和人脑在本质上是相同的**。

我们讨论人工智能是否有可能有意识时，我们却根本没有办法对意识作一个大家都认可的定义。如果我们不知道什么是意识，又怎么能判断人工智能是否产生了意识呢？

作者试图用以物理方式来研究意识时，难免无所适从。

自由意志

>德国哲学家叔本华《生活的智慧》（The Wisdom of Life）一书中写道：“每个人都认为自己先天的就是完全自由的，即使他的个人行为也是如此，并认为，每一个时刻，他都可以开始用另一种方式生活……但是，通过后天的经验，他惊讶地发现，他不是自由的，而是要受制于必要条件的。但尽管有了所有这些决议和思考，他还是不会改变他的行为，从生命开始到生命结束，他必须按照他的性格行事，即使连他自己也谴责这种性格。”

>沃尔弗拉姆的主要论点是，世界是一个大的IV级元胞自动机。他的著作《一种新科学》的书名正是基于要将这一理论与其他大多数的科学规律进行对比而命名的。

世界是确定的，但由于人类生命的短暂，而且这个回归过程是以无法理解的规则进行，所以，我们看到的是无序。

>如果宇宙是一个巨大的元胞自动机，正如沃尔弗拉姆博士假设的，就没有足够大的计算机可以运行这样一个模拟——因为每一个计算机将是宇宙的一个子集。所以，宇宙未来的状态就是完全不可知的，即使它是确定的。

回到了最初所有哲学家都无解的问题“我是谁”。作者的解决方案时，反正我们永远讨论不出结果，那么就简单点，只要与我的相同的思维基础，那么我就是我，至于有可能是多个我，或者更好的我之类，只是一个想法而已，只要你能接受，那么这就是对的。

>进化创造大脑的主要原因是为了预见未来。
>但是这种固有的对未来的预言是线性的而非指数性的，线性预测这种特质源于大脑皮质中的线性组织。这使我们想到，大脑皮质在不断预测：下面我们要看到什么词语、我们在拐角处想见到谁等。大脑皮质的每个部分都由线性组织构成，这说明我们不会自然而然地进行指数级的思考。小脑也会使用线性预测，如果我们要接一个飞过来的球，小脑会帮助我们进行线性预测，我们就知道在视线范围内球会落到何处，我们戴着手套的手应去哪里接球。

因为作者熟悉的计算机行业的摩尔定律，使得作者对于信息技术的指数级发展抱乐观的态度。这也是他认为这些技术会使拟脑的实现变的可行。

作者对于别人对他理论的怀疑逐条批驳，但是这类观点，其实谈不上批驳，只是对于相同事实的不同理解而已，只是作者有一点反驳的有点意思，就是关于模拟，一般认为大脑能进行模拟运算而计算机只能数字化运行，作者认为，所谓模拟只是数量问题而已，比如颜色，256色不行，那个1024色，大力出奇迹，大脑所谓的模拟运算，也是有一个量级的。

约翰·塞尔的“中文房间”思想实验，认为机器是不可能有意识的，因为如果你是房间中的人，你拿到一个问题，或者只是一串符号，然后在你手册中找到对应的回复，抄下来挮出去，完成一个交互，而不用理解这串符号是一个笑话还是一个令人伤心的消息。计算机正是这么做的，所以计算机不可能理解信息，也就没有灵魂。但是，作者提出一个聪明的反驳，就是，你认为手册是一个对应的列表，根据输入的符号输出对应的符号，但是，如果造物主是如此设计人类的，这个手册的内容更复杂一些，对应输入的符号的反应不仅仅是输出的符号，还在我们的大脑中嵌入了更多的反应，比如快乐、伤心等情感反应（这些反应也可以理解成手册的一部分），那么我们也可以按塞尔的定义，人类是没有意识的。

这和“自由意志"一样，因为我们对于意识也没有一个完整的定义。

>人类的独一无二之处在于：**我们制造工具，而工具让我们走得更远**。