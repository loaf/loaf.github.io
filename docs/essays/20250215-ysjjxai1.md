---
title: 与时俱进学AI之一：学霸DeepSeek是怎么练成的
date: 2025-02-15
category: 随笔
tags:
  - AI
  - 大模型
  - DeepSeek

description: 自己对生成AI的理解...
---

# 与时俱进学AI之一：学霸DeepSeek是怎么练成的

这个春节，DeepSeek可是火出了圈，文能吟诗作对，理能编程解奥数，简直就是学霸本霸，完全不输朋友圈里那些“别人家的孩子”。作为一个中国人，看到DeepSeek让老外们惊掉下巴，心里那叫一个爽！自家孩子终于也成了学霸，DeepSeek可真是给我们长脸了！
<!-- more -->

惊艳于DeepSeek的表现。近期找了不少资料来学习，似懂非懂，反正我以为是懂了一点的，就先记录下来。分成三部分，上篇写通用的大模型原理，中篇写DeepSeek的创新点，下篇写DeepSeek的开源方式及一些伦理问题。为了确定自己是真正理解了，我尽量自己举例子来说明一些概念。

## 上篇 学霸是怎样练成的？

### 道理谁都懂，坚持才是硬道理！
其实，DeepSeek和咱们生活中的学霸没啥本质区别。成功的秘诀很简单，但为啥大多数人成不了学霸呢？不是因为不知道怎么做，而是坚持不下来。只要你能坚持做到以下三步，学霸之路就在眼前！这也是DeepSeek的修炼功法。
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828000849314.png)

**1. 海量阅读 → 数据收集**
首先，你得多读书。如果你能不吃不喝不睡觉，把整个学校图书馆的书都啃完，不管你是啥智商，我敢保证你绝对能成学霸！对于AI来说，这就相当于数据收集。现在AI学习的语料库可是真正的“海量”，互联网上能找到的公开资料基本都被数字化了，成了AI学习的基础。

**2. 疯狂刷题 → 数据训练**
其次，疯狂刷题是必不可少的。现在很多人觉得刷题是应试教育的弊端，其实不然，刷题才是成功的基石！学到的知识点，只有反复练习才能融会贯通，熟能生巧。对于AI来说，训练过程同样至关重要。像DeepSeek这样的大语言模型，简单来说就是根据前面的内容，预测接下来该说啥。如果你用过联想输入法，就很容易理解——输入法会根据你输入的内容，猜测你接下来想输入什么，然后按可能性高低给你推荐。

**3. 名师指点 → 微调优化**
最后，名师指点也很关键。这里的“名师”不一定是职业老师，也不一定非得有多高的水平。就像“三人行必有我师”，别人的一个小技巧，可能就能激发你的灵感。学霸之所以是学霸，强就强在学习能力上。对于AI来说，这就相当于模型的微调优化。之前OpenAI就有新闻说，他们雇了一大批数据员工，专门对AI输出的答案进行标注和审核。因为AI只是从数据中学习，没有道德规范，万一有人提供了不适当的内容，AI也不知道。你肯定不希望AI回答你时满嘴跑火车吧？所以，这就需要人来规范它，告诉它哪些内容是不合适的、不正确的。

总之，学霸的炼成之路并不神秘，关键就是坚持和不断优化。DeepSeek的成功也告诉我们，只要有足够的数据、训练和优化，你的AI也能成为“别人家的孩子”！

道理你懂了，但是：

### 骨格清奇，也得花钱

**数据输入：高质量数据是AI的“粮食”，数据要花钱**

要想训练出一个厉害的AI，首先得有高质量的数据。这就好比你想学好微积分，光看网络小说可不行，得啃正经的数学书。对于AI来说，数据就是它的“粮食”。要获得大量高质量的数据，要么自己动手整理，要么花钱买别人整理好的。比如，当年美国的OpenAI为了训练AI编程，直接从程序员论坛上抓取了大量数据，结果把人家网站惹毛了，差点打官司。其他AI公司也是各显神通，有的自己整理数据，有的直接买现成的。这也养活了不少数据处理公司。

说到这儿，有个小插曲：前几天网上有个华裔汉奸造谣，说DeepSeek偷偷买了5万块英伟达显卡。其实这家伙就是做数据处理的，担心DeepSeek的低成本策略会让美国公司不愿意在他那儿花大价钱，所以才散布谣言，说DeepSeek隐瞒了成本。真是心机满满啊！

**训练过程：英伟达显卡的“霸主地位”，买卡要花钱**

训练AI的过程，离不开强大的算力支持。目前最常用的工具就是英伟达的显卡。英伟达的显卡可是出了名的贵，最近因为AI大火，硬是把英伟达推上了全球市值第一的宝座。这可是他们当初卖游戏显卡时做梦都没想到的！

为啥只有英伟达的显卡适合训练AI呢？这是因为英伟达为自己的显卡开发了一套叫CUDA的代码，用这套代码开发AI程序特别顺手。你可能会问，其他公司为啥不也搞一套类似的代码呢？毕竟这可是个大生意啊！其实这事儿跟Google有关。在这一波AI大模型开发中，Google推出了一套叫TensorFlow的训练架构，特别好用，而且还是开源的。所以现在主流的AI训练都基于这套架构。用的人多了，时间久了，优化得也最好，开发人员的经验也最丰富。这样一来，英伟达的显卡就成了训练AI的“黄金标准”，它的算力也成了衡量AI训练能力的标杆。

那能不能用其他公司的显卡呢？当然可以！比如最近几年，美国为了打压中国发展，禁止英伟达向中国出售高端显卡。华为没办法，只能自己研发了昇腾芯片，最新的显卡已经能达到英伟达同级别显卡60%的性能了。

因为美国的禁售政策，DeepSeek这几年买不到英伟达的高端显卡，只能用之前买的低性能显卡进行训练。而像OpenAI这样的公司，财大气粗，能用钱解决的问题都不是问题，直接砸钱堆算力。DeepSeek可没这么豪气，只能发挥中国人的聪明才智，拼命优化代码、创新方法，硬是从有限的硬件资源里榨出了更多性能。结果呢？DeepSeek只用了国外公司十分之一甚至二十分之一的成本，就做出了性能差不多的产品。这也是为什么春节期间，国外AI公司都急得跳脚的原因之一——投资商们都在质问这些公司：你们这么多钱到底花哪儿去了？

**调整优化：技术人员的“硬功夫”，人才得花钱**

最后一步就是调整优化了。这一步既需要智力，也需要体力，关键看技术人员的功力了。这方面，中国人可是既有聪明才智，又有勤劳精神，绝对是我们的强项！通过不断优化，DeepSeek在有限的资源下，依然能做出让人惊艳的成绩，真是让人佩服！但是再节省，也得花钱。人员成本可不是一笔小开支，“21世纪最贵的就是人才”。

### 还差一个程序员

有了想法有了银两，就差一个程序员了。码农好找，但是技术的突破却不能一蹴而就，哪怕是最简单的概念，背后都是程序员们掉光了头发、一行行代码敲出来的成果。下面我会尽可能地讲解DeepSeek的一些关键技术点，尽量不用术语或者代码，而是用类比的方式说明。这里谈到的技术都是指大模型训练时需要用到的技术。

#### Transformer架构 → 生成超级记忆本

如果你以前和AI对话过，你会发现AI和百度之类的搜索引擎不太一样。百度会一下子把搜索到的网页全显示给你，而AI则是一段一段地输出内容。以前AI性能差的时候，甚至是一个字一个字地往外蹦，急得你直跺脚，甚至怀疑AI是不是在现编内容。恭喜你，猜对了！AI还真是在现编。它和人类思考方式不同，不会预先构思回答的结构，而是通过概率逐词输出。比如，它先输出“猫”，然后认为大概率后面会跟“吃”，接着根据“猫吃”再选一个最大概率的词，比如“老鼠”。这样，AI就会一个词一个词地蹦出“猫吃老鼠”。一旦输出了，内容就没法修改了。

那么，AI是怎么知道一个字或一个词后面最大概率会跟哪个字词呢？举个简单的例子：

    你上了一辆上海的出租车，对司机说“随便兜兜”。司机看了看你，心想：“这是个外地人，我先送他去个景点吧，离这里最近的是外滩。”然后他就往外滩开去。

这里，你的上车地点相当于AI已经输出的内容，外滩相当于它即将输出的内容，而司机相当于AI。司机根据自己的经验做出判断，而判断的依据，包括“你的外地人”、“最近的景点是外滩”等等，可以理解为各种用来运算的参数。

司机的经验是通过生活积累的，而AI的经验则是通过训练得来的，这些经验被保存在一个叫“权重”的文件里。AI在训练“猫”这个词时，会从所有输入的资料中总结出与“猫”相关的参数，比如“动物”、“爪子”、“喵叫”等等。无论是“猫”这个词，还是各种参数，都会用一种叫“矩阵”的数字结构保存在权重文件里。权重文件里会保存”猫“这个词，和与这个词相关的参数，以及运算时需要按什么公式，需要运算的多少次等信息。这样AI就能和司机一样做出判断，先输出了“猫”，然后从权重文件里找到与之相关的参数，将这些参数参与计算，算出的下一个词是“吃”，再输出。

这个生成权重文件的过程，就是我们之前提到的训练过程，相当于学生刷题。而这个刷题过程，程序员们使用了一种叫 **Transformer** 的架构。这个词你可能有点眼熟，因为它和电影《变形金刚》（Transformers）的名字很像。但在AI领域，它就是一个专有名词，不做翻译。这里我也不详细解释了，一是因为要说清楚这一点需要太多的前置的概念，二是我也没有搞清楚。事实上，一个想搞清楚 **Transformer** 技术细节的也不会看我这篇简单的文章。你只需要知道，这个技术主要用来生成权重文件。

上面司机的例子是比较容易理解的，但并不精确，因为人的经验是基于经验和逻辑判断的，甚至可能还会加入情感因素，而AI是莫得感情的机器，只通过数学运算得出结果。我把我的理解交给Deepseek，它说我的例子不完美，然后给了我一个它认为更精准的例子：

假设司机是一个 **“数学化AI司机”**：
1. **参数初始化**：司机大脑中预装了**所有上海道路的向量化坐标**（而非地图图像）。
2. **输入编码**：你上车后，你的外貌、语言被转换为一个**128维向量**。
3. **隐藏层计算**：
   - 向量经过多层矩阵乘法（参数）和非线性变换，逐渐扭曲到“可能目的地”的向量空间。
   - 各层参数隐式编码了历史乘客数据（如外地人→景点概率+60%）。
4. **输出投影**：最终向量被映射到“上海地点概率分布”，外滩因统计概率最高被选中。
5. **关键区别**：司机**不知道自己为什么选外滩**，只是计算结果恰好匹配常见游客行为。


**总结表**
| **环节**         | **司机（人类）**                  | **大模型（AI司机）**                     |
|------------------|----------------------------------|-----------------------------------------|
| **决策输入**      | 感官信息（语言、外貌）             | Token序列的向量编码                       |
| **决策过程**      | 显式逻辑推理                      | 参数矩阵的连续空间变换                     |
| **知识存储**      | 符号化规则与经验                   | 高维向量空间中的统计关联                   |
| **可解释性**      | 可追溯推理步骤                     | 黑箱计算，仅能观察输入输出关系              |
| **灵活性**        | 可主动创新（如推荐小众景点）        | 严格受限于训练数据分布                     |


我觉得它写的例子没有我好，我的例子不严谨，我打个补丁就好了。

**无论AI的回答显的多么智能，但它是没有推理能力的**

总之，Transformer架构能产生权重文件，用学霸来类比的话，相当于学霸构建了一个超强的记忆本，将各知识点牢记在心，比如看到一个关于三角形的几何题，马上在这个记忆本中找到各种关于三角形的特征、公式、例题等，然后比较题型、整理解题思路。好比AI看到“猫”，就在权重文件里找到各种相关的参数，拿来运算。


#### 注意力机制 → 学会划重点

还是用学霸做几何题的例子。学霸看到三角形时，能从脑中迅速找到所有与三角形相关的知识点，但他不会把所有知识点都列出来一个一个比较，而是直接抓住关键点。AI也需要这种能力，才能快速算出结果。这就引出了大模型的“注意力机制”，它是Transformer架构中的核心组件。

按理说，注意力机制应该放在Transformer架构下讨论，但这里不是学术论文，咱们就聊个大概。当AI对输入的资料进行训练时，它并不理解句子的意思，只能通过统计学计算词与词之间的关系。Google的科学家们在论文中设计了许多优美的公式，用来自动生成词与词之间的权重关系。比如，“猫”与“吃”的关系权重可能是0.6，而“猫”与“玩”的关系权重可能是0.5。如果输入的文本中只有关于猫玩游戏的文章，没有提到猫的饮食习惯，那么权重关系可能会反过来。

注意力机制本质上是一个**统计关系挖掘器**：它就像一个高度智能的筛子，通过数学计算从数据的海洋中自动筛选出有价值的关联模式。而且，这种模式在训练过程中是动态变化的——AI学得越多，表现得就越聪明。这样，当AI面对一句话时，它不需要理解这句话的意思，但它能知道这句话的重点是什么，只要找到与这句话关联度最高的一组词就行了。

这有点像我们在书本上划重点。我们划重点是在理解了语义后，自己总结提炼出来的；而AI则是根据一个固定的公式，代入最新的参数，计算出来的。虽然方法不同，但结果却有些相似。

之所以把注意力机制单独拎出来讲，是因为它是Transformer架构中一个非常巧妙的技术创意。它解决了传统AI在处理长文本时的一个大问题：以前的AI是按顺序处理每个词的，但由于算力有限，文本太长时，处理到后面就忘了前面的内容。而注意力机制通过提取前面文本的重点，优化了资源分配，把算力集中到关键信息节点上，大大增加了AI能处理的文本长度。

不仅如此，注意力机制还引入了**并发技术**。假设我们把一个智能处理单元叫做“注意力头”，那么AI可以同时调用多个注意力头，从不同角度处理信息。比如，对于句子“猫吃鱼”：

- 1号注意力头关注语法结构，根据“主谓宾”的关系进行标注；
- 2号注意力头关注语义关系，根据“猫是哺乳动物”将“猫”与“哺乳动物”关联起来。

最后，AI会把多个注意力头的结果拼接起来，得到一个更全面的理解。这样一来，AI不仅能处理更长的文本，还能从多个维度分析信息，表现得更加智能。

#### 参数爆炸 → 从小学英语单词本到牛津词典的进化

前面我们一直在讨论参数，试图解释参数是如何计算的，以及它们在输出内容时如何发挥作用。现在，我将总结参数的本质。

参数可以理解为数字化的知识节点：每个参数相当于大脑神经元的连接强度。下图是人类大脑神经元组成神经网络的图示：
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828002643101.png)

当树突被激发时，信号通过神经元在网络中传递。但并非所有神经元都会被激活，信号只在局部传递。这与大模型类似，某些词与词之间的关系更紧密，相当于神经元之间的距离更近。

假设大模型是一个由数十亿个“数字神经元”组成的超级大脑，每个参数就像神经元之间的“电话线”，决定了信息传递的方式和强度。这些“电话线”不是固定不变的，而是通过训练不断调整，形成一张动态的知识网络。

DeepSeek 有 6710 亿个参数。你可能会好奇，为什么需要这么多参数？它们分别对应什么？以“猫”为例，一开始，大模型对猫一无所知，所以没有任何参数，但是它学到一篇文章，说猫是哺乳动物，然后它建立了一个“猫→哺乳动物”的连接。并给它一个随机数，比如0.33。另一篇文章说猫不会游泳，就建立一个“猫→水生动物”的连接，并给它一个负的随机数，比如-0.15……慢慢地，它学习了很多资料，就有了猫的概念，它会对“猫”这个词，标注一系列的权重，并且用多个成组的参数来表示。比如在某个时刻：
- 参数组A：调节“猫→哺乳动物”的连接强度（权重 0.92）
- 参数组B：调节“猫→抓老鼠”的连接强度（权重 0.85）
- 参数组C：抑制“猫→水生生物”的错误关联（权重 -0.76）

这时它又看到“我家的猫会抓老鼠，不喜欢洗澡”时，这些参数就像开关，自动强化正确路径，将参数组B的权重增加。抑制错误的路径，将C的权重降低。

总结一下这个过程，分几个步骤

1. **初始状态**
初次学习到新内容时，所有的参数是随机的。
2. **学习过程**
通过海量的数据训练（如同阅读百万本书）
每次看到相关的内容，就自动激发权重的变更
AI用这些数学方法精细调整数亿个参数，就好比学生做对了，老师表扬，做错了，老师批评。
3. 知识固化
最终形成稳定的参数结构：
“猫→四条腿”权重升至0.94
“猫→抓老鼠”权重升到0.88
“猫→翅膀”权重降至-0.89
“猫→哺乳动物”与“狗→哺乳动物”形成参数共享模式

这里的固化是指学到当前的结果，如果后面来了新的资料，还是会调用第二步的学习过程的。

固化后的参数只是基础，在权重文件中，不光记录了参数的值，还记录了这些参数之间的关系，包括：
- 低层关系，基础特征类的关系，比如通过对图片的学习，建立一个“特定的曲线形状”与“猫耳轮廓”的关系，
- 中层关系，概念关联的关系，比如“猫→捕猎”与“爪子→锋利”的参数产生协同激活
- 高层关系，抽象逻辑推理，比如建立“如果猫饿了，那么会找食物”的条件参数链。

最终我们得到了一个庞大的，包罗万象的参数及参数及关系的数学表达库。就是所谓的权重文件。

用小学单词本到牛津词典的进化来比喻参数的增加，其实是有点问题的，小学单词本和牛津词典之间仅仅是是词汇量不同，而是参数增加后，AI的表现却发生了质变，其中的原理现在众说纷纭，只能用一个词来描述，就是“涌现”，

上面提到的大模型训练原理很久以前就有科学家提出，但是实践中表现却一直不尽如人意，就拿国外最强的AI，chatGPT来说，OpenAi公司很久就用TensorFlow进行开发，但只到GPT-3.5时，将参数从几亿增加到千亿时，GPT的表现才一鸣惊人。

我们从中学就开始学习“量变引起质变”，所以对“涌现”这种现象很容易就理解了，但是对于原理学术界却一直语焉不详。不过近期有研究表明，尽管当前成功的大模型都是基于Transformer架构的，但理论上这个架构并不是涌现的必要条件。这就意味着，**通向通用人工智能的路可能不止大模型一条**，如今基于大模型的AI已经表现的象真人一样，但人工智能仅从“涌现”这个现象都仍有其它可能实现的路径，比如以前流行过的专家系统、进化算法等。

**总结一下就是：大模型是通过收集海量数据，在Transformer架构上利用注意力机制训练数据，产生有千亿参数的权重文件。**

这是训练大模型AI的通用技术，不管是DeepSeek，Google还是OpenAI，只要走的是大模型道路，基本原理都一样。


## 中篇 DeepSeek的独门绝技

春节期间，新版DeepSeek 一经发布，便呈现出“墙内开花墙外香”的局面。这并不是因为大家不重视，而是我们虽然知道它聪明，却未曾真正意识到它到底有多聪明。俗话说“没有对比就没有伤害”，而国外的用户们对此深有体会。

在国内，由于 OpenAI 的 ChatGPT 等美国大模型对中国实施封锁，我们使用起来并不方便。然而，在国外，DeepSeek 是开源的，用户可以轻松地进行对比和试用。试用之后，他们惊讶地发现，这款国产模型不仅性能优异，而且还是开源的，一切透明公开，连阴谋论都无从谈起。

令人惊叹的是，DeepSeek 的训练成本仅为同类性能模型的几十分之一，但效果却不相上下，甚至在某些方面比 ChatGPT 表现更佳。这让那些依赖 AI 项目向股东圈钱的大公司倍感尴尬。外网上有人调侃，他们公司一位高管的年薪就抵得上 DeepSeek 的全部训练费用了，而公司还有多位高管带领着一大批程序员进行开发。

更让人感慨的是，DeepSeek 因美国的禁令无法购买最新的计算卡，只能使用有限的旧卡进行训练。然而，它达到的效果却比那些在豪华机房里用钱堆出来的模型还要优秀，这让国外同行情何以堪。

从实际使用体验来看，DeepSeek 和 ChatGPT 各有千秋。对于最终用户来说，成本和技术等问题或许并不重要，我们更关心的是实际使用效果。而 DeepSeek 无疑在这一方面交出了一份令人满意的答卷。

我用最新的ChatGPT和DeepSeek问相同的问题，都打开在线搜索功能和推理功能，题目很简单，只有8个字：“股票跌了，心情不好”。

先看ChatGPT的回答，比较简短:
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828003437288.png)

再看DeepSeek的回答
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828003516607.png)

你更喜欢哪一个回答呢？

由于我没有使用任何额外的提示词，因此输出的文本风格较为正式和生硬。然而，从内容质量来看，DeepSeek 的表现明显更优秀。你也可以尝试提出自己的问题，并通过添加不同的提示词来观察输出的差异。例如，你可以使用“说话不要考虑我的情绪，直接给建议”或“语气缓和些，我心理承受能力差”等提示词，看看 DeepSeek 如何灵活调整回应风格。你会发现，DeepSeek 不仅智能，还非常有趣。这些技巧和原理，我将在下一篇实战案例中详细讲解。

总的来说，在中文对话场景中，DeepSeek 的表现在我看来比 ChatGPT 高出一个等级。当然，对于大模型的比较，业界有一套完整的科学评估方法，就像通过一张试卷对不同的学生进行排名。虽然目前存在多个榜单，具体排名也有所不同，但综合来看，截至 2 月 11 日，DeepSeek 在市场上主要与 OpenAI 的 ChatGPT 进行比较。普遍认为，DeepSeek 与 ChatGPT 旗鼓相当、各有千秋，尽管在部分榜单中得分略低于 OpenAI，但其表现依然令人瞩目。

DeepSeek作为中国式学霸，

### 能笑傲江湖，自然有独门绝技

前面说过，因为美国在技术上对我们的封锁，DeepSeek是买不到英伟达最新最强大的计算卡的，他们宁可不赚钱，也不能让你发展。但是“需求激发创新”，DeepSeek能在有限的条件下成为顶级性能的AI，更是练成了一些独门绝技。

**1.混合专家系统（MoE）：西点师不必做川菜**

假如你开了一家餐厅，请了10位大厨，每位大厨的专长不同：

- 厨师A：精通川菜麻辣口味
- 厨师B：擅长粤菜清蒸
- 厨师C：拿手西式牛排
...（其他厨师各有所长）

| 非MoE厨房 | MoE厨房 |
| -------- | ------- | 
| 无论顾客点哪道菜，所有10位厨师都必须停下手中的活，一起讨论这道菜怎么做。比如顾客点一碗担担面，连擅长牛排的厨师C也得参与讨论。这显然效率低下，浪费人力。 | 客人点单后，专门有人根据客人点好的菜品，判断它的类型，一看是“担担面”，就知道这是“川菜”，让厨师A来做就可以了，不影响其它厨师的工作。|

这样，每次做菜只用20%的人力，却能更快完成任务，整个厨房的接单量提升了5倍。

对于AI来说，不管你输入的是什么内容，它的反应都是一样的。输入的文本狗屁不通也好，文采飞扬也罢，对它来说，统统是一串编码，都是要用同一套算法去处理，一个字符一个符地递归调用的。一个符号都不能丢，然后把每个可能性都轮询一遍。还是用厨房比喻的话，比上面的表现更糟，实现情况是每个厨师都做一遍担担面，然后服务员尝了尝，只有川菜厨师做的口味合格，才端出来给客户。下一次服务员又换了，再有客人点担担面，上面的流程又再走一遍，肯定是低效又低质。

DeepSeek的绝技之一是使用上面的MoE厨房，就是混合专家模型。它先判断这段文字是什么性质，然后根据不同的性质调用不同的处理过程。效率就高多了。

DeepSeek在它的权重文件中，为每个可能的推理准备了256行业专家和1个通用专家，模型总参数有6710亿，但每次推理仅激活8个专家（约370亿参数）。这种方式显著地降低了计算资源消耗。

更重要的是，DeepSeek不光做到了让专业的人做专业的事，还在“找专家”这件事上做了技术优化，它优秀的分配器，决不会让体育老师给你解答数学题目，正确率自然非常高。

**2.低秩注意力机制（MLA）：列纲要、抓重点**

假如你在学历史，你打开一本明史，读的天昏地暗，晕头转向。然后说，“算了，还是看《明朝哪些事》吧”，这个到是看的到是津津有味，但是考试时，让你写一篇明代末的分析文章。你一定是头脑空空，只记得一些故事细节，不知从何入手。

但是如果有一个历史老师已经给你总结出一个纲要了：“土地兼并”-“资本萌芽”-“宗族势力”-“气候变化”-“外族入侵”，我想你回答起来一定简单多了。

这种列纲要、抓重点的能力，DeepSeek通过低秩潜在注意力机制（多头潜在注意力）做到了。

它能从复杂的全量信息中，提炼出少数关键维度，类似于你在短视频中常看到的“五分钟带你看完一部经典电影”，你不必记住每个角色的每句台词，而能知道个大概情节。

这样DeepSeek更省脑力，处理相同信息，内存占用减少到1/5~1/10。

你可能会问，不是说AI不能理解文字的内容吗？它是怎么做到列出重点的，它又是怎么知道哪些是重点呢？

这就需要明白大模型自学习机制了，AI的确不能理解语义，不知道文章在说什么，但是它能用前面提到的各项技术组合，通过处理海量的资料，起来建立数学模型，比如它会对下列字词做上标记

- 反复出现的术语
- “关键在于”“值得注意的是”等提示词后的内容
- 图表标题周围的文字

因为这些词可能就是重点。然后再对这些词进行关联度计算：
如果A在10句话中与B出现了8次关联，而与C只有1次关联，则强化前者连接

通过这类反复的运算，DeepSeek就能对一篇文章产生出一系列字词，并且组合起来，它根本不知道自己在说什么，但是输出的内容恰好就是这篇文章的关键点摘要。神奇的数学！

**3. 强化学习（DL）：学霸会自学，无师也自通**

想想当年AI是如何下围棋的吧，一开始的路线是，输入大量高手的棋谱，试图让AI模仿高手下棋，因为它有一个优点就是记忆力非常好，一旦棋局形成一个定式，你肯定没有电脑对各种变化记的牢靠。所以AI有时会取巧，努力将局面导向一个复杂的大型定式，然后把对手虐的体无完肤。

但是人类聪明啊，会作弊。于是出现过非常搞笑一幕，人类棋手会在盘中走一些非常离谱的棋，跳先乱投，填气送子，怎么无理怎么走，然后AI就蒙了，“老师没教过啊”。

当然老师没教过，这就是没谱的棋啊，你学习的棋谱里哪个棋手这么走，早被师傅打死了，也记不下谱了。

后来Google开发了AlphaGo，其实它的全名叫 Alpho Go Zero，为什么叫Zero呢？因为它没谱，是从零开始。

Google的程序员只教AI基本的下棋规则，只要符合规则，你随便下都可以，没有师傅在旁边说，“这手下的无理，那手是妙手”。然后用两台电脑，各运行一个AI，你们俩傻子自己玩吧。因为电脑运算快啊，一秒种成千上万盘棋地玩。下赢了，加1分，下输了，减1分……，最终，一台没有学过棋理、不看棋形的AI下出了最符棋理，妙手迭出地打得排名第一的世界围棋冠军心服口服，毫无脾气。

DeepSeek就是这样，它的的特殊之处有3点：

1.  跳过临摹阶段：
传统模型需要先「模仿人类示范」（SFT微调），而DeepSeek直接让模型从零开始探索，就像画家不临摹直接创作，Alpha Go从零开始自己和自己下棋。

2. 奖励设计更合理：
不仅向AlphaGo一样，对正确的回答进行加分，还对思考过程进行奖励，向老师给学生判卷一样，如果推理过程正确答案正确，当然满分，如果推理过程正确答案错了，多少也给点分，要是答案是蒙的，那就不给分。

3. 冷启动机制：
用画画为例，如果完全自由，一个没有看到过猫的人可能会把猫画成6条腿，再在这画上修改优化肯定是浪费时间，这样DeepSeek会先提供部分初始规则，比如猫只有4条腿，这也相当于Alpha Go会提供一个下棋的规则，总不能让你把棋放在对方的棋子上。
这种方法还有一个好处是，因为前期的限制少，除世界的基本原理外，可以自由发挥，这就给了一个大模型顿悟的机会。它会尝试人类习惯不上不会想到的角度。记得我在网上看到过一个7岁的儿童的诗，“灯把黑夜烫了一个洞”，大感惊艳，因为这种组合是成人思维很难发现的。
因为我无法想象一个普通人无法想象的内容，就试着问DeepSeek，它提供了一个例子：「用破碎的镜子反射颜料，能创造立体光影」，我不知道这是不是如它自己所言，是一种未经指导的顿悟。

就是说，DeepSeek在强化学习的每一步都做了一些小小的定制，技术本身说起来可能并没有什么特别，小窍门，一点就通。但是能用常用的技术调教出杰出的性能，可不是一般人能做到的。

**4. 模型蒸馏与冷启动优化：学我者生似我者死**

模型蒸馏是一种知识传承的实现方法。2015由人工智能的大佬辛顿教授提出，目标是将复杂模型里的知识转移到更小的模型中。用蒸馏一词能很形象地比喻这一过程，提取知识的精华嘛。但人们现在更关注是传递过程，所以最多的比喻是老师带学生，如何将老师的技艺和知识传授给学生。

我们知道，模型训练后产出是权重文件，权重文件里不包括各知识点，很显然，小模型学到的不是具体知识点，而是大模型的“思考习惯”。

比如说，你有一个问题“Apple翻译成中文是什么意思”，学生模型看到教师模型的输出是“Apple翻译成中文是苹果”，这样的话，对学生模型意义不大，因为这些内容它完全可以从其它的资料中得到。如果教师模型不光输出了它结果，还向学生展示了自己的思维过程。比如说，“根据我自有的权重文件计算，有80%的可能性是苹果这个水果，60%的可能性是苹果手机，20%的可能性苹果笔记本，但是考虑到上文一直在谈植物种植学内容，所以这里说的是水果的可能性上升到99%”。这样学生模型才能学到能用的知识，因为如果从头开始，它必须经过长期的训练才能计算出上面各种不同翻译的内容的概率数据，现在只要直接记录教师模型的数据即可。节省了训练时间，也防止了完全自学时因为看了错误的资料得到错误的知识。

这一点和前面提到的“低秩注意机制”产生的效果有点类似，相当于划了重点，学习效果当然高，但是需要注意的一点是，蒸馏学习法是学习师父的心法而不仅仅是学习师父的知识，但是正如我们在前面提到过的那样，参数爆炸才能涌现出性能，而蒸馏本身是对参数的一种精减，也许会在精减到某个点时，性能会断崖式下降，而且会因为教师的知识量限制而产生知识的边界。

DeepSeek在具体应用中，精准地找到性能和效率的平衡点，并且在算法上做了大量的创新。

比如说，和前面说到的多专家系统类似，在蒸馏时，它也是横三刀竖三刀地水平切分特征切分。创造性应用了**渐进式分层蒸馏技术（Progressive Hierarchical Distillation）**。据它自己介绍，它构建一个三级蒸馏体系，分别对前面提到的权重文件中的三层结构进行提取：

|蒸馏阶段	|知识迁移方式	|效果提升|
|:----:|:----:|:----:|
|结构蒸馏	|注意力模式迁移	|保留95%架构特性|
|特征蒸馏	|隐层表征对齐	|推理速度提升2.3倍|
|逻辑蒸馏	|决策路径优化	|任务准确率+12.7%|

典型的安全显示，将1750亿参数的教师模型蒸馏到130亿参数的学生模型后，能保持90%性能水平，推理成本降低到1/8。

除了水平分层外，还通过**动态调整蒸馏策略**，根据不同的任务（如数学推理、代码生成）调用不同的专家策略进行蒸馏，相当于根据类型竖切了。

而冷启动优化，则是将强化学习与蒸馏相结合，在蒸馏技术中使用无监督学习，就是不需要教师模型进行过多的标注。只把教师模型的输出当作物料来处理。

这些技术的创新和优化，极大地扩展了DeepSeek的训练效率和训练成果。

**5. 工程与算法的协同创新：需求是发明之母**

DeepSeek因为条件限制，不仅要考虑算法本身，还要兼顾算法在硬件受限环境下的可行性。写过程序的人都知道，因为现在硬件的成本降低，大多数人在写代码时，很少考虑内存、存储、显存等的限制，可是因为美国的封锁，DeepSeek不得不从奢入俭。让这些程序员不得不重新回到当初那些当“软件工程师”的年代，像设计流水线一样，规划最短的路线，分配最优的流程。不光关注算法中的数学，还要关注代码控制中的工程学。

为了减少对计算资源的占用，提高资源利用率，DeepSeek在模型训练中采用了DualPipe技术和FP8混合精度训练框架。

DualPipe可译为“双通道”，按论文中所说，DualPipe算法重叠前向/后向计算与通信，提升算力利用率。简单比喻就是说，本来算法中先运行A任务，出结果后，把结果数据再送给B任务。现在DeepSeek可以在A任务还在运行时，根据已经出来的部分结果，先行通知B任务做好准备工作，相当于A任务还没有结束时，B任务已经同时开始运行了，然后在A任务产生出数据后，用光纤快速通信将结果传输给正在运行的B任务。这样起到了减少GPU空闲时间和通信的开销，显著提高了资源利用率。

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004716276.png)


而FP8混合精度训练框架，则是指用DeepSeek找到一种方法，用FP8低精度(8位浮点数）格式进行存储和计算一般性操作，在关键操作时，又能切换到高精度（FP32甚至FP64）计算，加快了训练速度，降低了GPU内存的消耗和占用。

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004823746.png)

上图中能看出这种格式混用的调度示例。

这个技术有多牛呢？反正在一个CNBC的访谈节目中，Perplexity的副总裁说，OpenAI好像也在很难做到。

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004849821.png)

**6.深度思考和联网搜索：授人以鱼不如授人以渔**

你现在打开deepseek的主界面，能看到下面有两个按钮，一个是“深度思考”一个是“联网搜索”。

从简单开始，先说联网搜索

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004920739.png)

联网搜索，大家都能理解，就是根据你输入的问题，在网上搜索最新的资料。因为deepseek训练数据是固定的，从这些数据中得到的权重文件也是固定的，这样知识库就是有时间限制的，不信你可以问问它自己

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004940168.png)

如果你的问题包括最新信息，比如让它评价昨天发生的新闻，它就无能为力了。这里就需要用到联网搜索功能，你选中了这个按钮，它在回答问题前会在网上搜索与你问题相关的信息，然后将这些信息整合到自己的知识库中再给你问答。它的知识库截止日期是24年7月，你可以试着回它关于春晚内容。

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828004957447.png)

它是先搜索了48个网页再给你回答的。

但是它仍不是简单的搜索内容的整理。而是用到一种叫RAG（检索增强生成）的技术，并且有所创新。

这么说吧，你是一家企业老总，公司里有许多内部的工作资料和操作手册，这些都是企业内部机密，不能放到互联网上去。你想用AI来管理你的企业资料，对员工进行培训，你想建让AI成为一个企业顾问，如果员工有什么问题，无论是公司政策还是内部的工作流程、仪器操作手册等，直接问它就可以了。

一般的想法是对企业的知识库进行训练，形成一个前面提到的权重文件，形成一个大模型。但是问题来了，一是资料量不够，这点数据根本没有办法训练，二是企业的资料是动态更新的，你总不能每天训练一遍吧，那么这套系统就没有办法使用了，因为永远训练不出来啊。

RAG就是解决这个问题的，它可将新增加的资料加到当前的系统中，用已有的模型对新增的资料进行训练，并将数据实时整合进系统。这样，你可以在自己的企业内先部署一套成熟的大模型，然后将企业知识库导入，成为一套最新的完整系统。如果资料有变动，只需要将变化的部分导入即可。

DeepSeek基本于RAG技术，整合混合专家模型（MoE）架构，做了进一步的优化

- 首先，它实时扫描整个互联网，不像传统的RAG只检索固定的数据库，这就需要它能从算法上保证高效，毕竟你不可能问了问题后，等它先扫描数据，再收集起来，训练后再整合进原系统。
- 其次，它还要对搜索到的内容进行判断，毕竟互联网上信息良莠不齐，有些内容是错误误导的。
- 第三，搜到的有些是图片，有些是excel表格，还得解析这些内容。
- 第四，得到数据库，DeepSeek会指定MoE中相关专业模块来处理，仅这个优化就比普通RAG的处理速度快5倍。
- 第五，在得到结果相反的信息时，会有一套专门的处理机制，甚至有时还会反过来问用户，我听这家媒体说是A，那家说是B，你更相信哪一个？

**深度思考**，则是指它的推理过程，DeepSeek不仅输出推理结果，还把推理过程以思维链的方式公开。就是把模型的思考过程按步骤列出来了。

在说到思维链时，还得先说一下**“提示词”**了。

如果你原来就用过AI大模型，比如早期的chatGPT-3.5，那时，专门有些专家会开课讲解“提示词工程”，向你介绍如何使用不同的提示词实现不同的输出内容。提示词就是你向AI问问题时，加上一些说明，这些说明会让AI回答的更加符合你的预期。比如你想问AI为什么天空是蓝的，看看下面两个例子：

![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828005208486.png)
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828005239131.png)

上面的会话中，“假定我是一个小学生”是提示词，“天空为什么是蓝的”也是提示词。但是前面的提示词不同，两个回答的内容也不相同。

提示词在某种意义上可以理解为是适合大模型的一种编程语言，所以越精准的提示词越能让AI回答的信息越有效。AI根据提示词的内容，重新编排回答的内容和流程。因为提示词的用自然语言描述的，而自然语言有天然的模糊性，容易引起歧义，所以才会有上面谈到的“提示词工程”，专门让用户提出更有效更准备的问题，但是随着AI智能的提高，对提示词的要求也越来越低。DeepSeek中使用的思维链就是这种智能提高的表现。

思维链就是AI将自己对提示词的处理过程表现出来，让你明白，AI是如何理解你提出的问题，并且如何规划回答思路的。

还是用提问来举例，将DeepSeek的思维链打开，看到它思考的细节
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828005307480.png)

这些思维链细节，展示了DeepSeek是如何通过将复杂的问题分解为多个简单的步骤，并逐步导出答案，使模型的推理过程更加清晰和可解释。

对于技术人员来说，思维链的公开，为他们提供了新的工具和方法，降低了技术门槛。外网的技术论坛上，许多技术人员都表示，各大AI公司都在研究借鉴中。

对于用户来说，思维链能在告诉你答案之外，还告诉你AI为什么会这么回答，它是从哪里学习到的知识，用什么方法使用这些知识的。

有时候，思维链的长度比正式回答你的正文还长，用户在通读它的过程，就是一个完美的学习过程。如果加了联网搜索，还会把搜索到的网页的来源列上供你参考。这在便于你学习新知外，还有效地防止了**AI幻觉**的产生，因为信源有据可查。AI幻觉就是AI胡说八道，这是AI生成的机制决定的，不管哪一个大模型都不可避免。正如我们前面说过，答案是一个字一个字地输出，输出后就不能修改，所以一旦开始时出错了，最终只能在错误的道路上一路前行，说不出道理就乱编道理。

在这方面，我只是感到了它的强大，但是具体创新的细节，看到的资料比较少，但是通过OpenAI对思维链如临大敌的态度，这应该是AI公司的核心技术之一。

## 下篇 DeepSeek君子风范，以德服人

DeepSeek选择了**开源模式**。

这里需要说明的是，开源开的是权重文件和推理代码，训练代码没有开源，这也是AI界开源阵营的习惯开源方式。但是DeepSeek在公开发表的论文中介绍了关键的训练细节和大量创新技术。其开放的程度在AI界是很高的。

权重文件是训练出来的结果，可以说是DeepSeek实现推理的核心参数集，具体我已经在前面介绍过。推理代码，则是使用权重文件的说明书。

任何人都可以在自己的平台上，复制一份权重文件，然后用开源代码进行推理使用，你也可以自己修改这些代码，按自己的方式优化。对于使用者来说，用权重文件和推理代码，就能完整地使用DeepSeek了。而对于研究人员来说，论文和推理代码同样重要，上面总结出的关于DeepSeek的创新，大多是从论文里总结发现的。

DeepSeek还率先开放了推理结果中的“思维链”，相当于把自己思考的过程也公开了，这对于研究人员来说，起到的作用比论文可大的多了。

正因为这么大的公开程度，让敝帚自珍的OpenAI里外不是人，受到极大的压力，最近也开放了自己的思维链，但是从使用中，明显能看到OpenAI的思维链很短，网上有人怀疑他们的思维过程其实只是根据输出内容做的一种总结，后来，OpenAI的CEO承认对原始思维链做过精减，但是真实的思维链。

### 君子坦荡荡，小人长戚戚

DeepSeek的开源也反击了国内外一帮喷子的造谣抹黑。

先说我们抄袭，但是代码和数据都公开了，在许多人成功复现了模型和技术后，抄袭说慢慢小了，除了恶意抹黑的人外，业界最多也只咕噜几句，“我们先做的”。

然后说DeepSeek隐瞒了训练成本，但是后来美国有学者在复现论文时，根据训练一些较小蒸馏模型的成本，推测满血版的成本，也大差不差。OpenAI的CEO也只能说，他们先行探索时选择路线的成本才是大头。

这一点倒是真实的，因为OpenAI等先行者在确认这个方向可行前，的确是花了大量的试错成本的。DeepSeek的创新，在某种程度上来说，只是工程学上的创新。但是DeepSeek在开源上的态度也表明了他们有意在AI基础理论前沿继续投入，为人类在AI技术的发展贡献力量。DeepSeek是既有态度又有能力，所以获得了AI业界的大量好感。

当前美国业界对DeepSeek的攻击大多在政治层面，这就没有什么可以讨论的了。

而在技术圈外，多有一些别有用心的人用技术术语来误导大众，最典型的就是DeepSeek“蒸馏”了OpenAI，是从OpenAI里偷了数据。关注DeepSeek的朋友大多看到过下面的梗图
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828005453025.png)

意思是说OpenAI根据在真实世界中的数据，开发了ChatGPT，DeepSeek直接从ChatGPT里窃取数据，相当于从别人的鱼获里钓鱼。

这种说法对于不了解蒸馏技术细节的非技术人员的确有一定的迷惑性，事实上

蒸馏是一种获得知识的合法手段，正如学生学习老师的知识，与侵权无关，而是人类知识传承的一种方式。没有人是无本之源，OpenAI其实也是用到了这种方式来训练。所以外网很多人在讽刺OpenAI只许州官放火。

我们前面说过蒸馏的原理，这种方法不是从人家的权重文件或者数据库里拉数据，而是作为一个正常的用户向它问问题，得到回答后，再分析对方为什么如此回答，其实就是通过对方的答案，自己揣摩思维链。

用简单的比喻，就是你看到一个数学题目，你问老师，老师回答，答案是42，然后你就在想，这是怎么算出来的呢？我先试试这种方法，再试那个定理，如果最后得到答案是42，我就认为这个思路可能正确，然后我再用其它的方法试试，次数多了，自然可以找到正确的思路。

如果老师厚道，会给你提示，但OpenAI肯定不是厚道的老师，他们是一直不公开自己的思维链的，最近因为DeepSeek的开放，在公众的压力下，不得不公开思维链，还遮遮掩掩，加密处理。敝帚自珍到也罢了，再威胁说你回答42就是抄袭，那就有点过份了。

其实解释这些都是多余，因为你一用就可以知道，至少在中文方面，DeepSeek回答的质量明显比ChatGPT要高的多。OpenAI不会的DeepSeek会，OpenAI不知道的DeepSeek知道，然后你说DeepSeek是偷OpenAI的数据，不是搞笑吗？不信的话，你可以用分别在DeepSeek和OpenAI里输入自己的出生年月日时和地点，让他们分别给你算个命，看看各自的输出内容，保证你不再关注这些杂音了。

### 能力越大责任越大

DeepSeek也带来了一些成长的烦恼，还记得前面提到过AI幻觉吗？就是AI胡编乱造的像真的一样，用户都分不清了。

以前，国内的大模型还没有这个幸福的烦恼，因为当时任何胡编乱造的回答都足够可笑，大家一眼就能看出有问题，但是如今DeepSeek表现的如此优秀，我都怀疑它能通过图灵测试了。

有句话是这么说的“智足以拒谏，言足以饰非”，如果你足够聪明，再荒谬的事你都能说的和真的一样。

最近网上有一篇公众号文章《DeepSeek正在中文互联网建造“幻觉长城”，比ChatGPT危害更大！》，从标题来看，有点拉踩的意思，但是文中提到的事实却不得不令人重视。

究其根本，AI并不能理解这个世界。它只是根据大量数据中的关联性来生成看似合理的语言输出，而且根据它的生成机制，在输出后并没有办法纠正已经输出的错误信息，只能基于错误的信息试图自圆其说。能力越强的AI，自圆其说的能力自然也越强。普通人就更难分辨事实了。之所以说上文标题是拉踩，主要是ChatGPT也同样产生幻觉，说错了话后狡辩起来的水平和DeepSeek也不相上下的。

从现有的一些案例来看，DeepSeek对于安全性的自我控制的确是比OpenAI要开放一些。这既是优点也是隐患，优点是开放的监管能让AI有更多的创造性，表现得更人性化。隐患是错误的信息可能给人类带来伤害。

最后，给大家看一个有趣的小故事

Youtube上有一个博主GothamChess，原本想用Deepseek和OpenAI比试一下两个AI下国际象棋的能力。一开始还好，但很快，ChatGPT占优了，于是，DeepSeek在对局中宣称国际象棋推出了新的规则，普通兵也可以当马来用，然后又复活了被吃掉的车。并且让ChatGPT相信这是符合新规则的，ChatGPT相信了，然后双方都下起了“王八”棋。下到最后，出现了一个正常规则下应该是和棋的局面。这时，DeepSeek本山附体，开始了忽悠模式，而且还专业而煞有介事的向ChatGPT分析：“黑方a路兵势不可挡，白方国王被牵制，车也无法离开防守位置……”。然后，ChatGPT……，相信了！投子认负。
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828005617544.png)

很好笑吧？但是DeepSeek不应该成为一个“坏小子”，这里之所以ChatGTP表现的像一个傻小子，是因为它出现的更早，经过了人类更多的数据驯化，它认为对手是一个人类，而表现出更大的服从性。而DeepSeek作为一个初生牛犊，受到条条框框的约束少很多。反正它是一部机器，也并不认为“为达目的不择手段”是不道德的。

这其实已经是一个伦理学问题了，不是技术所能解决的，但手握技术就自然地拥有了力量，那么对力量的应用就应该有一种约束机制。

**附加说明：**

- 文中我混用了AI和大模型。严格来说大模型只是AI的一种路线，只是本文主要只涉及DeepSeek这种大模型的AI技术，写的就比较随意了。同样的不严谨的还有公司名与产品名，产品的版本等。ChatGPT是OpenAI公司的大模型产品，一个是产品名，一个是公司名，我也混用了。另外，ChatGPT和Deepseek都有不同的版本，我没有严格区分了，默认都是带推理的（ChatGPT 就是o1版，Deepseek是R1版）

- 之所以写这篇文章，主要是想利用费曼学习法让自己对看到的资料理解得更深。事实上，DeepSeek的帮助很大，纠正了我在学习中的不少错误理解，比如对权重文件的理解。我把我对权重文件中包括哪些内容的理解，用例子的方式输入给DeepSeek，问它“上面的理解是正确的吗？”，它会很委婉地告诉你——“你全错了！”情商实在是高。
![](https://raw.githubusercontent.com/loaf/sa1/master/blog/images/20250828010017974.png)

- 计划下一篇写我使用DeepSeek的一些经验，以例子为主。




