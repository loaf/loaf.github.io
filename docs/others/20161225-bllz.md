---
title: 面对技术进步，我们纠结些什么？——读《玻璃笼子》
date: 2016-12-25
author: loaf
category: 其它
tags:
  - 阅读
description: 

---


# 面对技术进步，我们纠结些什么？——读《玻璃笼子》

<!-- more -->

当我们享受自动档汽车的方便时却怀念手动档的操控感，这种纠结的心情每个人都可能会遇到。  

但技术进步带来的并不只是个人体验的变化，事实上，它已经改变了我们的社会结构，书中的第二章就涉及到这个问题。按资本主义的经济周期的惯例，经济下行，就业率下降，经济回升，就业率上升，但是2009年以后的美国经济现状好像破坏了这个规律，因为自动化减少了就业的需求，（当然，这本书谈的是自动化，所以，机器是替罪羊，如果是一本谈全球化的书，全球化就是替罪羊。）不管什么原因，就业率没有上升，或者就工资水平没有同步修复的确是事实，也许会的新的职业的产生，但是这些变化总是会有滞后，总会有一大批劳动力成为牺牲品，这种现象导致了经济的增长的红利并没有让普通民众享受到，这也正是近年来“华尔街运动”和今年“特朗普当选”这些事件的社会基础。  

我们考虑技术进步时，担心人工智能未免过于简单化，其实即使不涉及任何“智能”，自动化、工业化对人类文明的改变也是潜移默化但快速进行的。  

第三章中作者以最早在飞机上使用的自动驾驶技术为例，说出了我们在享受便利的同时可能的危害，其实这甚至都算不上危害，那是就自动驾驶技术让飞行员的技术越来越差。  

第四章重塑工作和工人，的确提到一个越来越明显的变化，就是技术让人变笨了，这种笨是因为人们不需要思考，不动脑子能完成工作，所以工作的性质就发生了变化，可以说，自动化改变了工作也改变了工人。技术让聪明人变笨了，也让笨人可以从事原来只有聪明人才能从事的工作，对于人类而言，如果聪明人相对于笨蛋没有进化优势的话，人类只会越来越笨。但是再想一想，好像我们漏掉点什么，这些让人聪明的技术是谁创造谁维护的呢？如果人类变笨了，没有了创造和维护这些技术的能力，这些技术自然也就消失了，那么它能带来的负作用自然也会消失，所以，我们好像不用太担心这个啊。再深入一步，如果人工智能更进一步，能代替人类创造和维护，那么还是需要担心啊！当然，在这一章里，作者提到了另一个与自动化相关的案例，涉及到人类的行为模式，尽管是以一个老鼠的实验为例子，在让老鼠做出正确选择的刺激中，弱电击和强电击的效果都不如中等程度的电击效果来的好。套到自动化这个主题上来，工人在面对自动化时，如果自动化程度过低或者过高都会让工人的工作能力和工作效率降低，如同一个U型曲线的两端，只有中等程度的自动化才是适当的自动化，但令人遗憾的是，如何定义这个自动化的程度呢？  

其实人类的生理结构已经被技术进步不停地改进着，只是最近的技术发展的如此迅速，使得这些变化以我们可以感知的速度发生，才引起了我们的反思和恐慌。正如所有的其它事物一样，如果一个渐变突然加速，而且越来越快时，就是质变开始出现的时刻。生存或者毁灭，人类也许很快就会面临抉择。  

一般情况下，人类是一个系统中最薄弱的环节，最容易出现故障或错误的节点就是有人参与的节点，那么，一个完全自动化的系统是不是合理的呢？否定的理由有，1）任何系统可以说在某种程度上都是专家系统，它受制于人类的经验，那么，即使它能完美地匹配99%的情况，也无法正确地应对意外的场景。2）自动化因为高效，所以一旦失控，造成的危害远远大于人类所能造成的危害，甚至会出现对人类生存产生危害。第一种情况，我们也许还可以接受，但是第二种情况，就是无解的了，不管它能带来多少的好处，我们都承受不起一次失败。所以，我们在考虑技术的发展时，不得不引入人文主义。但是，这种情况在现实中必然出现一种危险，就是，对于技术能力的自我限制或者自我审查，没有办法做到公平，破坏规则者会取得优势。  

以上我们谈论的都是技术本身对人类能力的影响，其实是忽略了很重要的一点，就是伦理。  

书有有2个例子给人印象深刻，自动驾驶的汽车面对突然出现在前面的宠物，是选择救狗而冒翻车的风险还是牺牲狗而确保你的安全？如果那是你熟人的狗或者你自己的狗，如果你车上还有小孩，这个选择会有不同吗？（p208），还有就是当你选择用扫地机器人时，它是不会区分灰尘和小虫的，当一只蟋蟀经过时，机器人会直接吞进去，但是有些宗教信仰的人，可能会停下手中的工作，捡起蟋蟀带到门口放生。而当我们按下机器人的按纽时，我们就给了它权力，代表我们做出了道德选择。  

但是，没有完美的道德算法并不是机器的错，人类可能犯的错误更多，事实上，不管我们给机器编制什么样的道德规则，从宏观上来说，都比人类自身表现的更出色，更有道德。书中还有一个更极端的例子：杀戮机器（p211）以增加将道德选择托管给机器后，给人的恶劣感觉。但是，在我看来，这只是一种推托之辞，当然，让一个人类士兵来做选择，责任只会由这个个体来承担，但让机器来做选择，责任则会变成由人类来承担。  

好吧，我们可以更进一步，假如我们同意了一套道德标准，怎么让机器去接受呢，书中说，一种方法是从上而下，如同阿西莫夫的机器人三原则一样，但是因为“我们无法预测机器人可能遭遇到的所有情况。自上而下变成的严格性会弄巧成拙”（p214），另一种方法是自下而上，就是“机器人被嵌入一些基本的规则，然后投入使用，这种方式利用机器的自觉技术，培养机器人自己的道德编码，并根据遇到的新环境加以调整。”，听起来是不是就是机器人自己的“进化”过程？但是，这样产生的机器人道德也许早就偏离了人类的道德观，是人类不能接受的，再说了，在试错过程中的代价是人类能承受的起的吗？  

当我们把技术放入黑箱时，想得到的是一个能高效实现目标的劳动工具，但是，作者从另一高度铨释了我们工作的意义，那就是：“工作，让我们找到了自己”。这似乎不应该出现在一个思考技术进步的文章中，因为这更像是一种无奈的托辞，面对无解的问题，我们只能一退再退，为我们失败的努力寻找借口。正如，自动档汽车代替了手动档，所以，我们才怀念“驾驶的乐趣”  

我们可以反思，我们可以置疑，但我们却不得不接受技术正在一点点地改变人类，从生理到心理，从道德到伦理。在技术面前，我们的所谓红线越画越近，要求越来越低，现在，我们只要希望面对的技术黑箱能变成一个玻璃笼子，我们能看到它在运作，尽管我们仍然不理解它为什么如此运作，但至少能给我们一个虚幻的安全感，那就是：是我们在控制着这一切。
